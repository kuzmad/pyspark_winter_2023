{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EAL7YbIqGFr"
   },
   "source": [
    "**Занятие первое**\n",
    "\n",
    "Начнем с простого. Многие знают что такое map и reduce операции, но все же для закрпеления мы их тут реализуем. Ах да, не забудем и про shuffle. Делать все будем на упрощенной задаче с word count для ознакомления с самим подходом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DBUYlacS6nb"
   },
   "source": [
    "На самом деле мы рассмптрим все в упрощенном виде, но это даст нам понимание, как можно через hadoop streaming, например, писать самописные map и reduce операции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHxuTfZ1TKc9"
   },
   "source": [
    "! mapred streaming \\\n",
    "  -input /wiki/sample.jsonl \\\n",
    "  -output /word-count \\\n",
    "  -mapper \"/opt/conda/bin/python3.6 mapper.py\" \\\n",
    "  -reducer \"/opt/conda/bin/python3.6 reducer.py\" \\\n",
    "  -file mapper.py \\\n",
    "  -file reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe2aSFz_Tgqv"
   },
   "source": [
    "Выше mapper.py и reducer.py это программы, которые выполняют одноименные операции нам потоком информации из jsonl файла, записывая ответ в файл word-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hGAAKrdu5d-",
    "outputId": "049b1e3f-378e-4399-a1e5-cd11557c2737"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPXzd-YMtqcO"
   },
   "source": [
    "Давайте загрузим файл с текстом и посмотрим на него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKUCkYpBp9Lt"
   },
   "outputs": [],
   "source": [
    "with open('spark_text.txt', 'rb') as f:\n",
    "    data = f.readlines()\n",
    "data = [text.decode() for text in data if text.decode() != '\\r\\n']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CywPTchftnqK",
    "outputId": "e6952263-6266-415d-9361-9a449fa3f5bb"
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "0wRwGdoJ5pQs",
    "outputId": "74da6396-3a7e-4b24-a076-46d93d4537c0"
   },
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydjOU0HLwCZq"
   },
   "source": [
    "Как бы мы сделали..\n",
    "Надо немного почистить слова, а также сделать все в парадигме MapReduce. Понятно, что можно все написать проще, но мы ведь хотим понять, как это работает=)\n",
    "\n",
    "Загрузим стоп слова, очистим от них текст, приведем к нижнему регистру, всем раздадим ключи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-zIUslxxtyQ"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOXxYSKI2EfQ",
    "outputId": "007979aa-8205-49e1-f75f-462568ad3f00"
   },
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDK6W4MUewdv"
   },
   "source": [
    "пунктуацию тоже полезно бы удалить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "XhrSCeUJ2MKZ",
    "outputId": "cfa3a9fd-00e8-4c2b-bc0b-fa446aa12d4c"
   },
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0AjYtsiv9tc"
   },
   "outputs": [],
   "source": [
    "def mapper_text(text):\n",
    "    clean_text = re.sub(rf\"[{string.punctuation}]\", \"\", text)\n",
    "    words = nltk.word_tokenize(clean_text)\n",
    "    words_with_value = [(word.lower(), 1) for word in words \n",
    "                        if word not in stop_words]\n",
    "    words_with_value = sorted(words_with_value, key=lambda x:x[0])\n",
    "    return words_with_value\n",
    "\n",
    "def create_chunks(shuffled_data):\n",
    "    result = {}\n",
    "    for idx, data in shuffled_data:\n",
    "        if idx in result:\n",
    "            result[idx].append(data)\n",
    "        else:\n",
    "            result[idx] = [data]\n",
    "    return list(result.items())\n",
    "\n",
    "def shuffle_text(mapper_result, n_nodes=5):\n",
    "    shuffled_data = []\n",
    "    for key, value in mapper_result:\n",
    "        shuffled_data.append((hash(key)%n_nodes, (key, value)))\n",
    "    shuffled_data = sorted(shuffled_data, key=lambda x: x[0])\n",
    "    chunks = create_chunks(shuffled_data)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# на самом деле для reduce в жизни пишут иначе..не зря мы сортируем внутри map\n",
    "#данные по ключам. Это нужно для избавления от этапа проверки ключа и поиска\n",
    "def reduce_text(values_to_reduce):\n",
    "    result = {}\n",
    "    for key, value in values_to_reduce:\n",
    "        if key in result:\n",
    "            result[key] += 1\n",
    "        else:\n",
    "            result[key] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7qztZ0ijcqf"
   },
   "source": [
    "Проверим, что все работает\n",
    "\n",
    "Сначала map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "133g98tQMT8I",
    "outputId": "cf08ffd4-edf6-4a86-d224-d7bb5a6c7dc3"
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpqqPnNRhCXp"
   },
   "outputs": [],
   "source": [
    "map_stage = mapper_text(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hiOXuxSsDno",
    "outputId": "df8debdd-5a1b-44c0-b635-d9b29f52f99f"
   },
   "outputs": [],
   "source": [
    "map_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoOq2kxGl4FM"
   },
   "source": [
    "shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLyQcJ7Xjmll"
   },
   "outputs": [],
   "source": [
    "shuffle_stage = shuffle_text(map_stage, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ig2vthBFsNTm",
    "outputId": "a1436c8d-52ef-48ef-df6d-fa5d0b4c48bc"
   },
   "outputs": [],
   "source": [
    "shuffle_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rqyNgzpl8q1"
   },
   "source": [
    "reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJed4iQsll9i",
    "outputId": "72da51e1-6987-407f-eaaf-7295ed766f14"
   },
   "outputs": [],
   "source": [
    "reduce_text(shuffle_stage[4][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOuqRbx5srNh"
   },
   "source": [
    "Итак, осталось все рассчитать параллельно и собрать результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NgoQwpasxwq"
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3ogNEUhtvkD"
   },
   "outputs": [],
   "source": [
    "n_nodes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rA9awfQ4RSo"
   },
   "source": [
    "Обернем в 1 функциию для удобства map и shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TItZtKEF4Qiu"
   },
   "outputs": [],
   "source": [
    "def map_shuffle(text, n_nodes):\n",
    "    map_result = mapper_text(text)\n",
    "    shuffle_result = shuffle_text(map_result, n_nodes)\n",
    "    return shuffle_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WOywHRItFWD",
    "outputId": "ecaa9062-0ad2-4ce0-a3f7-abf0d4c4a774"
   },
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
    "    res = parallel(delayed(map_shuffle)(df, n_nodes) for df in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIfatYoXMjPW",
    "outputId": "015f407a-8909-44fa-cc49-b15b019c1eed"
   },
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EgpGGu9MknD",
    "outputId": "c9f7073a-5c00-4503-f619-dbf87112f925"
   },
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvAYM5vA9K8N"
   },
   "source": [
    "Сделаем что-то вроде перессылки, собирая все в словари и заодно посмотрим на сколько равномерно распределлиись наши слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kTLnBO24013"
   },
   "outputs": [],
   "source": [
    "shuffle_stage = {i:[] for i in range(5)}\n",
    "for values in res:\n",
    "    values = dict(values)\n",
    "    for key in values.keys():\n",
    "        shuffle_stage[key].extend(values[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9sAjyP46kUE",
    "outputId": "f9310ac8-0a73-4e5c-f594-a1670b71893c"
   },
   "outputs": [],
   "source": [
    "for key in shuffle_stage.keys():\n",
    "    print(f'{key}: number of words = {len(shuffle_stage[key])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVEA-LZG9eEv"
   },
   "source": [
    "И последний этап - нужно сделать reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5i95b8FbDboX",
    "outputId": "9c3b897f-4e05-430b-cf68-4d0861a92497"
   },
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
    "    res = parallel(delayed(reduce_text)(shuffle_stage[key]) for key in shuffle_stage.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkGsGeKE7FeS",
    "outputId": "50bb92f6-8db8-426f-8a02-6a2731163adc"
   },
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8on05jYEMxUp",
    "outputId": "f0e4c915-3907-4e33-da52-f34e236ece3b"
   },
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZsgvg9oEVwt"
   },
   "source": [
    "Собираем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVKdO8eAD24r"
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for partition in res:\n",
    "    for key in partition.keys():\n",
    "        if key in result:\n",
    "            result[key] += partition[key]\n",
    "        else:\n",
    "            result[key] = partition[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUTsOJf7EtW1",
    "outputId": "067818de-4a94-4037-b4ab-ea522f5ff037"
   },
   "outputs": [],
   "source": [
    "sorted(result.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OViND9SFFTOd"
   },
   "source": [
    "Да, было бы проще все сделать иным кодом и в один проход, но целью было разобрать, как все это примерно работает под капотом на больших данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhK08F7hFjv_"
   },
   "source": [
    "**Домашнее задание**\n",
    "\n",
    "Посчитать количество рейтингов больше 4 для каждого фильма и вывести фильмы в порядке убывания количества этих оценок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPx9_0-wFlK-"
   },
   "outputs": [],
   "source": [
    "with open('user_ratedmovies.dat', 'rb') as f:\n",
    "    data = f.readlines()\n",
    "headers = data[0].decode().split('\\t')[:3]\n",
    "data = [row.decode().split('\\t')[:3] for row in data[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8yWQm0zJegy",
    "outputId": "20c31439-a718-4e1d-a113-878243a6c132"
   },
   "outputs": [],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgDpQdAeRG5e",
    "outputId": "251f8369-b897-4465-bfae-93782a55c088"
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ln4GFhQZH5tM",
    "outputId": "9d1b38ba-13a4-4a1e-bb33-f90b5a3e26f2"
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzkqhk9MRL8P"
   },
   "source": [
    "Пишем map, shiffle и reduce + параллелим вычисления. Лучше задавать batch_size при распараллеливании, либо даже заранее все разбить на батчи, будет быстрее\n",
    "\n",
    "Также посмотрите на то, нет ли перекоса в данных после shuffle, можете попробовать использовать остаток от деления не простого hash, а ввести какую-то функию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1aUiwrJRK3W"
   },
   "outputs": [],
   "source": [
    "def map_rating(row):\n",
    "    pass\n",
    "\n",
    "def create_chunks(shuffled_data):\n",
    "    pass\n",
    "\n",
    "def shuffle_rating(mapper_result, n_nodes=5):\n",
    "    pass\n",
    "\n",
    "def reduce_rating(map_row):\n",
    "    pass\n",
    "\n",
    "def map_shuffle(text, n_nodes):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJdLsomDRyS0"
   },
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_nodes, verbose=10) as parallel:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmKhm2eeRyVZ"
   },
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_nodes, verbose=10) as parallel:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed0nAHrDSMcX"
   },
   "source": [
    "После reduce все можно собрать в одном цикле, считаем, что данные переслали после на 1 машину и агрегируем"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
